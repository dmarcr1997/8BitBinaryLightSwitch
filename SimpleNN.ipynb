{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNt8GIQdTC/c9oAocl3N2In",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dmarcr1997/8BitBinaryLightSwitch/blob/main/SimpleNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dh4m0azlBC9s"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#-------------Forward Pass------------\n",
        "def forward_pass(x, w1, w2):\n",
        "  h = x * w1\n",
        "  y_hat = h * w2\n",
        "  return h, y_hat\n",
        "\n",
        "#-------------Loss Function-----------\n",
        "def mse_loss(y, y_hat):\n",
        "  return 0.5 * (y - y_hat) ** 2\n",
        "\n",
        "#-------------Gradients (Backprop)----\n",
        "def compute_gradients(x, w1, w2, y):\n",
        "  h, y_hat = forward_pass(x, w1, w2)\n",
        "  dL_dy_hat = (y_hat - y)\n",
        "  dL_dw2 = dL_dy_hat * h\n",
        "  dL_dw1 = dL_dy_hat * (x * w2)\n",
        "  return dL_dw1, dL_dw2\n",
        "\n",
        "#-------------Training loop-----------\n",
        "def train_network(x, y, w1_init, w2_init, alpha=0.01, epochs=10):\n",
        "  w1 = w1_init\n",
        "  w2 = w2_init\n",
        "  for epoch in range(epochs):\n",
        "    h, y_hat = forward_pass(x, w1, w2)\n",
        "    loss = mse_loss(y, y_hat)\n",
        "    dL_dw1, dL_dw2 = compute_gradients(x, w1, w2, y)\n",
        "    print(f\"Iteration: {epoch + 1:2d}\\n\"\n",
        "          f\"w1={w1:7.3f}, \"\n",
        "          f\"w2={w2:7.3f}, \"\n",
        "          f\"y_hat={y_hat:7.5f}, loss={loss:8.5f}\"\n",
        "    )\n",
        "    w1 -= alpha * dL_dw1\n",
        "    w2 -= alpha * dL_dw2\n",
        "  return w1, w2\n",
        "\n",
        "#---------Run--------------------------\n",
        "if __name__ == \"__main__\":\n",
        "  x = 2.0\n",
        "  y = 20.0\n",
        "  w1_init = 2.0\n",
        "  w2_init = 0.5\n",
        "  w1_final, w2_final = train_network(x, y, w1_init, w2_init, alpha=0.01, epochs=14)\n",
        "  print(f\"Training Complete\")\n",
        "  print(f\"RESULT: y=x*w1*w2={x*w1_final*w2_final:7.5f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1q6XMMHBERz",
        "outputId": "6fda640a-fd97-4f60-e050-9613ea022544"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration:  1\n",
            "w1=  2.000, w2=  0.500, y_hat=2.00000, loss=162.00000\n",
            "Iteration:  2\n",
            "w1=  2.180, w2=  1.220, y_hat=5.31920, loss=107.76294\n",
            "Iteration:  3\n",
            "w1=  2.538, w2=  1.860, y_hat=9.44257, loss=55.72969\n",
            "Iteration:  4\n",
            "w1=  2.931, w2=  2.396, y_hat=14.04532, loss=17.72910\n",
            "Iteration:  5\n",
            "w1=  3.216, w2=  2.745, y_hat=17.65811, loss= 2.74224\n",
            "Iteration:  6\n",
            "w1=  3.345, w2=  2.896, y_hat=19.37178, loss= 0.19733\n",
            "Iteration:  7\n",
            "w1=  3.381, w2=  2.938, y_hat=19.86670, loss= 0.00888\n",
            "Iteration:  8\n",
            "w1=  3.389, w2=  2.947, y_hat=19.97382, loss= 0.00034\n",
            "Iteration:  9\n",
            "w1=  3.391, w2=  2.949, y_hat=19.99495, loss= 0.00001\n",
            "Iteration: 10\n",
            "w1=  3.391, w2=  2.949, y_hat=19.99903, loss= 0.00000\n",
            "Iteration: 11\n",
            "w1=  3.391, w2=  2.949, y_hat=19.99981, loss= 0.00000\n",
            "Iteration: 12\n",
            "w1=  3.391, w2=  2.949, y_hat=19.99996, loss= 0.00000\n",
            "Iteration: 13\n",
            "w1=  3.391, w2=  2.949, y_hat=19.99999, loss= 0.00000\n",
            "Iteration: 14\n",
            "w1=  3.391, w2=  2.949, y_hat=20.00000, loss= 0.00000\n",
            "Training Complete\n",
            "RESULT: y=x*w1*w2=20.00000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gya0I2N5ug75"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}